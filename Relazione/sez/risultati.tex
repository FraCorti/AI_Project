\section{Risultati}
Dopo aver visto come abbiamo deciso di implementare gli algoritmi e le metodologie presi in considerazione, passiamo ora a vedere i risultati ottenuti.
\subsection{Reti neurali}
Per quanto riguarda le reti neurali, i risultati ottenuti sono i seguenti.
\subsubsection{Reti neurali con Dropout}
\renewcommand{\arraystretch}{1.4}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{1.2cm}|p{1.2cm}|p{1.2cm}|p{2cm}|p{1.2cm}|p{1.2cm}|p{2.5cm}|}
			\hline
				\textbf{Epoch} & \textbf{Loss}    & \textbf{Acc} & \textbf{Binary accuracy} & \textbf{Val loss} & \textbf{Val acc} & \textbf{Val binary accuracy}\\ \hline
				1 & 0.1800 & 0.9419 & 0.9419 & 0.0555 & 0.9854 & 0.9854 \\ \hline
				2 & 0.0326 & 0.9905 & 0.9905 & 0.0796 & 0.9843 & 0.9843 \\ \hline
				3 & 0.0088 & 0.9978 & 0.9978 & 0.0563 & 0.9865 & 0.9865 \\ \hline
				4 & 0.0039 & 0.9992 & 0.9992 & 0.0729 & 0.9865 & 0.9865 \\ \hline
				5 & 0.0024 & 0.9997 & 0.9997 & 0.0863 & 0.9854 & 0.9854 \\ \hline
				6 & 0.0021 & 0.9997 & 0.9997 & 0.0887 & 0.9865 & 0.9865 \\ \hline
				7 & 0.0018 & 0.9997 & 0.9997 & 0.0945 & 0.9865 & 0.9865 \\ \hline
				8 & 0.0017 & 0.9997 & 0.9997 & 0.0993 & 0.9877 & 0.9877 \\ \hline
				9 & 0.0016 & 0.9997 & 0.9997 & 0.1026 & 0.9877 & 0.9877 \\ \hline
				10 & 0.0017 & 0.9997 & 0.9997 & 0.0965 & 0.9865 & 0.9865 \\ \hline
		\end{tabular}
		\caption{Risultati test rete neurale con dropout\label{}}
	\end{center}
\end{table}
\renewcommand{\arraystretch}{1}
\renewcommand{\arraystretch}{1.4}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			 \textbf{loss} & \textbf{acc} & \textbf{binary accuracy} \\ \hline
			0.1885  & 0.9857 & 0.9857 \\ \hline
		\end{tabular}
		\caption{Risultati validazione rete neurale con dropout\label{}}
	\end{center}
\end{table}
\renewcommand{\arraystretch}{1}
Dai risultati notiamo come già alla prima iterazione, la rete neurale con dropout riesca ad avere ottimi risultati fino ad arrivare alla decima iterazione del training in cui l'accuratezza e l'errore risultato infinitesimali.\\
Questo aspetto è osservabile anche nel set di validazione nel quale il risultato è eccellente. Si denota quindi una buona divisione del dataset nelle porzioni di training, validazione e verifica.
\subsubsection{senza Dropout}
\renewcommand{\arraystretch}{1.4}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{1.2cm}|p{1.2cm}|p{1.2cm}|p{2cm}|p{1.2cm}|p{1.2cm}|p{2.5cm}|}
			\hline
			\textbf{Epoch} & \textbf{Loss}    & \textbf{Acc} & \textbf{Binary accuracy} & \textbf{Val loss} & \textbf{Val acc} & \textbf{Val binary accuracy}\\ \hline
			1 & 0.4319 & 0.8628 & 0.8628 & 0.4045 & 0.8778 & 0.8778 \\ \hline
			2 & 0.3404 & 0.8651 & 0.8651 & 0.4793 & 0.8711 & 0.8711 \\ \hline
			3 & 0.2472 & 0.8948 & 0.8948 & 0.6005 & 0.8352 & 0.8352 \\ \hline
			4 & 0.1529 & 0.9453 & 0.9453 & 0.7931 & 0.8352 & 0.8352 \\ \hline
			5 & 0.0956 & 0.9652 & 0.9652 & 0.9669 & 0.8206 & 0.8206 \\ \hline
			6 & 0.0689 & 0.9722 & 0.9722 & 1.0665 & 0.8105 & 0.8105 \\ \hline
			7 & 0.0523 & 0.9781 & 0.9781 & 1.1933 & 0.8161 & 0.8161 \\ \hline
			8 & 0.0417 & 0.9784 & 0.9784 & 1.2961 & 0.8217 & 0.8217 \\ \hline
			9 & 0.0380 & 0.9792 & 0.9792 & 1.4842 & 0.8419 & 0.8419 \\ \hline
			1 & 0.0369 & 0.9804 & 0.9804 & 1.4484 & 0.8217 & 0.8217 \\ \hline
		\end{tabular}
		\caption{Risultati training rete neurale senza dropout\label{}}
	\end{center}
\end{table}
\renewcommand{\arraystretch}{1}
\renewcommand{\arraystretch}{1.4}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|c|}
			\hline
			\textbf{loss} & \textbf{acc} & \textbf{binary accuracy} \\ \hline
			1.6114  & 0.8063 & 0.8063 \\ \hline
		\end{tabular}
		\caption{Risultati test rete neurale senza dropout\label{}}
	\end{center}
\end{table}
\renewcommand{\arraystretch}{1}
Dai risultati notiamo come il miglioramento sia costante, la rete neurale senza dropout riesce ad avere discreti risultati fino ad arrivare alla decima iterazione del training dove l'accuratezza e l'errore risultato buoni anche se non ottimi.
Questo aspetto si nota anche nel set di validazione nella quale il risultato è buona, si sottolinea quindi la presenza di una sproporzione nel dataset che deve essere colmata con metodi aggiuntivi.
\subsubsection{Cos'è il "Dropout"}
Il \textit{Dropout}, è una tecnica che può prevenire il fenomeno dell' \href{https://en.wikipedia.org/wiki/Overfitting}{overfitting} che spesso si verifica allenando le reti neurali.\\
Il termine dropout fa riferimento proprio al fatto di ``far cadere'' e quindi escludere, per un breve periodo, una porzione nodi dalla rete neurale nelle fase di training. Questo permette alle unità di non co-adattarsi troppo.\\
Le unità che vengono temporaneamente nascoste sono scelte in modo casuale.\\
Per maggiori informazioni riguardanti la tecnica del dropout si 
veda \href{http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf}{Dropout: A Simple Way to Prevent Neural Networks fromOverfitting}
\subsection{Logistic regression}
\renewcommand{\arraystretch}{1.4}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			&\textbf{Precision} & \textbf{Recall} & \textbf{f1} & \textbf{Accuracy}\\ \hline
			\textbf{Spam} & 0.989  & 0.876 & 0.929 & 0.979 \\ \hline
			\textbf{Ham} & 0.978  & 0.998 & 0.988 & 0.979\\ \hline
		\end{tabular}
		\caption{Risultati fase di test logistic regression\label{}}
	\end{center}
\end{table}
\renewcommand{\arraystretch}{1}
Dai risultati notiamo come l'accuratezza e la precisione arrivino ad un ottimo livello sia per i messaggi di tipo "Spam" che di tipo "Ham", cosa che non si verifica nella metrica di recall per lo "Spam". Questo è dovuto al dataset non bilanciato nella quantità di record delle due categorie. \\
Si può affermare comunque che il risultato ottenuto dalla logistic regressiom, sia più che positivo.\\
Ci teniamo a sottolineare che, volutamente, non sono state prese precauzioni riguardo al dataset e ai suoi problemi di sbilanciamento.